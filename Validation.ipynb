{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validate Custom Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best.onnx\n",
      "best.pt\n",
      "last.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace the path with your specific path\n",
    "directory_path = os.path.expanduser('runs/detect/train4/weights')\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "contents = os.listdir(directory_path)\n",
    "for item in contents:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.9.13 torch-1.8.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\valid\\labels.cache... 273 images, 0 backgrounds, 0 corrupt: 100%|██████████| 273/273 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:43<00:00,  2.43s/it]\n",
      "                   all        273        401      0.772      0.726      0.785      0.456\n",
      "green_pedestrian_light        273         74      0.862      0.811      0.881      0.527\n",
      "  red_pedestrian_light        273         42      0.772      0.929      0.933      0.605\n",
      "         traffic_light        273        285      0.681      0.439      0.541      0.235\n",
      "Speed: 1.7ms preprocess, 142.8ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000113056779D0>\n",
      "fitness: 0.4886221535987539\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.52728,     0.60497,      0.2348])\n",
      "names: {0: 'green_pedestrian_light', 1: 'red_pedestrian_light', 2: 'traffic_light'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.7719708394002561, 'metrics/recall(B)': 0.7259929102034365, 'metrics/mAP50(B)': 0.7850683815429421, 'metrics/mAP50-95(B)': 0.4556836838271774, 'fitness': 0.4886221535987539}\n",
      "save_dir: WindowsPath('runs/detect/val3')\n",
      "speed: {'preprocess': 1.6875223362402165, 'inference': 142.8135166238079, 'loss': 0.0, 'postprocess': 4.461420324695853}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the model path and dataset configuration\n",
    "model_path = 'runs/detect/train4/weights/best.pt'  # Adjust this to your model's path\n",
    "# data_yaml = '/content/blind_assist1-2/data.yaml'  # Adjust this to your dataset's YAML path\n",
    "\n",
    "# Initialize the model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Perform detection on validation dataset\n",
    "# Assuming 'val' images are specified in your data.yaml under 'val' key\n",
    "results = model.val()\n",
    "\n",
    "# Print results or process them further as needed\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
