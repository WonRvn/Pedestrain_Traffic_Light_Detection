{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inference with Custom Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openvino-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\05-wilson-main4_jpg.rf.03b150c3a761fe0174da4acc9e1f4a60.jpg: 640x640 4 not-gos, 157.6ms\n",
      "image 2/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\0_ACP_HDE_150216Bwork_06_jpg.rf.4449d2cca43d3c54cdf7aeb4ea56c13c.jpg: 640x640 3 not-gos, 114.7ms\n",
      "image 3/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\1133906_1_seoimage4x3_ie-171930_4c347c2a65894020b6deba9136e6ea95_jpg.rf.bb44a9b20c5a5d36143d6b9b568e45a2.jpg: 640x640 2 not-gos, 130.0ms\n",
      "image 4/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\1200x0_jpg.rf.6e7b425c836d75340b8ce23aaeaa1600.jpg: 640x640 1 not-go, 118.7ms\n",
      "image 5/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\149618483_-cvqHzFbDImpN8g7aASZ3A3AdSesfjz8timij-u9Gww_jpg.rf.d0667eeb9a641c2fa5a2baecb0a8dbd0.jpg: 640x640 (no detections), 116.7ms\n",
      "image 6/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\200px-Lwr_Mount_Street_by_the_Grand_Canal-_Dublin-_-_Coppermine_-_4671_jpg.rf.a8b64c2450c7ff867ebff9975d2fc8f8.jpg: 640x640 1 not-go, 121.2ms\n",
      "image 7/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\200px-Mellor_traffic_lights_in_Donaghmede_Dublin_-_Coppermine_-_15568_jpg.rf.d9dc88173d09ed881a3cfe474a1f6124.jpg: 640x640 2 not-gos, 140.8ms\n",
      "image 8/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\201807_05_batterypt_sandybayrd_b68_stgeorgestce_jpg.rf.6aafdb8ec12e5a12e17a303fe5db6175.jpg: 640x640 2 not-gos, 126.9ms\n",
      "image 9/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\27094_ac46a6db2fed4cb98884d053d31a48a1_1541525900_jpeg_jpg.rf.42722480d2ec3759cbfa3de8d8024bd7.jpg: 640x640 (no detections), 188.6ms\n",
      "image 10/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\4182bd07c99a3c7e300162a30b38a02a_jpg.rf.691a315bbe6e51280dd54b2a2df89755.jpg: 640x640 1 not-go, 141.9ms\n",
      "image 11/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\KJP6QLO6BVB3BD3BG4244DWFQA_jpg.rf.669dc187a894791725ea60de159376cf.jpg: 640x640 3 not-gos, 148.5ms\n",
      "image 12/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\Sig_3173-e1572460133885_jpg.rf.ecaa091a633fbf4f8aa78fc7631d236d.jpg: 640x640 (no detections), 124.9ms\n",
      "image 13/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\Stop_Light_Wide_jpg.rf.56cefb0417d93ed4727bea9184284cf5.jpg: 640x640 3 not-gos, 126.9ms\n",
      "image 14/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\a5377a24-3ce7-4741-9142-6fd73b2597d7_scaled_jpg.rf.35f392a67a910e1809c5857121db15ae.jpg: 640x640 (no detections), 115.3ms\n",
      "image 15/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\ampeln-rot-grun-400-75677667_jpg.rf.fc8b21a4f22639bbd676dc400e3bcc9d.jpg: 640x640 3 gos, 2 not-gos, 119.4ms\n",
      "image 16/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\article-1388711-00533F3D00000258-208_1024x615_large_jpg.rf.f04d908c47eb7c4e60a5fdcf99036cf7.jpg: 640x640 4 not-gos, 123.3ms\n",
      "image 17/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\depositphotos_107649870-stock-photo-red-traffic-signal-on-the_jpg.rf.40bf0019a2e942bfd1cd059666c10d77.jpg: 640x640 1 not-go, 120.2ms\n",
      "image 18/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-801-_JPG.rf.9a788f490e09335df05bce4c724683bd.jpg: 640x640 1 go, 139.2ms\n",
      "image 19/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-804-_JPG.rf.ec3f188d87126d5318fcdafc3991e497.jpg: 640x640 (no detections), 156.5ms\n",
      "image 20/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-806-_JPG.rf.f6a4f3ade45a2a3f7f40adbf5fe42f4c.jpg: 640x640 (no detections), 127.6ms\n",
      "image 21/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-808-_JPG.rf.727a14a7291d07273152912b5e0c272b.jpg: 640x640 1 go, 121.6ms\n",
      "image 22/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-809-_JPG.rf.9365d3e7a0e627406799bc85f8803578.jpg: 640x640 (no detections), 114.0ms\n",
      "image 23/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-810-_JPG.rf.d2662537a79db34acc3f10f428f1411e.jpg: 640x640 (no detections), 113.3ms\n",
      "image 24/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-813-_JPG.rf.4d83bc1740a2f52bba06fa4c3aedcffa.jpg: 640x640 1 go, 106.3ms\n",
      "image 25/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-814-_JPG.rf.ab3fda364f0b19f525bb01d44da62e7f.jpg: 640x640 1 go, 131.9ms\n",
      "image 26/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-816-_JPG.rf.299a4396d9ceee55c7694261d706df57.jpg: 640x640 3 gos, 198.8ms\n",
      "image 27/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-817-_JPG.rf.7841a4abd15eb871a788d717d08860e3.jpg: 640x640 (no detections), 178.5ms\n",
      "image 28/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-824-_JPG.rf.424c05563b8dad1b81c8258cdde83aea.jpg: 640x640 (no detections), 153.3ms\n",
      "image 29/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-825-_JPG.rf.84fee92bb90b260972ec13b19f8c09c9.jpg: 640x640 2 gos, 173.5ms\n",
      "image 30/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-828-_jpg.rf.2574e3a27e39626888e5ad8375ed91de.jpg: 640x640 1 go, 182.2ms\n",
      "image 31/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-846-_jpg.rf.688e8b25b0e02dafae65ffd2d53be6f1.jpg: 640x640 1 go, 159.1ms\n",
      "image 32/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-849-_jpg.rf.04d575ae89f93e40a71198ea7a2c80dd.jpg: 640x640 2 gos, 160.1ms\n",
      "image 33/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-856-_jpg.rf.884606cbcbaa0699205d2127b1bd7290.jpg: 640x640 3 gos, 179.3ms\n",
      "image 34/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-861-_jpg.rf.8d41ddc83fe4c43eac1ced6263dd5d2c.jpg: 640x640 3 gos, 187.0ms\n",
      "image 35/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-863-_jpg.rf.89853fe4d7149f6dbfdbacc7545bff87.jpg: 640x640 3 gos, 182.1ms\n",
      "image 36/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-866-_jpg.rf.ad495ebab7d729782830fb88f145f688.jpg: 640x640 2 gos, 188.3ms\n",
      "image 37/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-867-_jpg.rf.a13bece7b1c64e33503cf581963b7d7a.jpg: 640x640 2 gos, 170.8ms\n",
      "image 38/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-871-_jpg.rf.98a367505646cf605fb3473fab4247c3.jpg: 640x640 2 gos, 178.3ms\n",
      "image 39/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\gpl-875-_jpg.rf.d2f659e15e36e7ce03149366c6ba1c58.jpg: 640x640 3 gos, 169.3ms\n",
      "image 40/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\how-trafic-lights-works_jpg.rf.957ad353033da500e70406cc9d3e6aed.jpg: 640x640 1 go, 1 not-go, 163.8ms\n",
      "image 41/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\image004_jpg.rf.6bdc2b6947a98790168aab3f9f5f6b97.jpg: 640x640 2 not-gos, 181.0ms\n",
      "image 42/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-1-_jpg.rf.356c6583ceebe7f5d4d62bcdafbbb762.jpg: 640x640 1 not-go, 192.6ms\n",
      "image 43/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-11-_jpg.rf.22dc413d7f39c657f37d625ac0c0f1f4.jpg: 640x640 (no detections), 186.7ms\n",
      "image 44/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-12-_jpg.rf.ba9400a7b8ff1e659805235c913a6f20.jpg: 640x640 1 not-go, 227.4ms\n",
      "image 45/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-17-_jpg.rf.888803d4b4eeca28a14b21d9bb441ee8.jpg: 640x640 (no detections), 110.2ms\n",
      "image 46/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-19-_jpg.rf.10b8ffe20de47e2807a6601729e3b50d.jpg: 640x640 (no detections), 143.7ms\n",
      "image 47/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-21-_jpg.rf.6c2038f09e62d19ef6008f355f7c2200.jpg: 640x640 1 not-go, 174.4ms\n",
      "image 48/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-22-_jpg.rf.14e05bcb0445cf34b8a885862854a70d.jpg: 640x640 2 not-gos, 126.1ms\n",
      "image 49/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-27-_jpg.rf.d72ca4ca0ded15876123f996eb7f5ed7.jpg: 640x640 (no detections), 138.4ms\n",
      "image 50/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-28-_jpg.rf.0b3550130b010fcdbe8efbbafa764b70.jpg: 640x640 3 not-gos, 157.7ms\n",
      "image 51/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-29-_jpg.rf.23dd57692eaea08c8a982e5dde38e079.jpg: 640x640 1 not-go, 146.2ms\n",
      "image 52/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-30-_jpg.rf.3ac8e09e4fad0896da1959a4bc1a4e67.jpg: 640x640 1 not-go, 124.7ms\n",
      "image 53/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-31-_jpg.rf.7777b170f467e689499d8601ba54c738.jpg: 640x640 (no detections), 127.1ms\n",
      "image 54/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-34-_jpg.rf.9c444101dc48291be5e79b122cd70884.jpg: 640x640 1 not-go, 120.9ms\n",
      "image 55/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-36-_jpg.rf.9b6d03de9d6c280e520f7303edc55afd.jpg: 640x640 2 not-gos, 168.7ms\n",
      "image 56/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-37-_jpg.rf.007b011c97727a4342eafd23f6dd02e4.jpg: 640x640 2 not-gos, 105.8ms\n",
      "image 57/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-38-_jpg.rf.14934ffff8415340c41452ec725e54c5.jpg: 640x640 1 not-go, 133.6ms\n",
      "image 58/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-5-_jpg.rf.81dce563d948dfcdcfb732fc2df07cba.jpg: 640x640 1 not-go, 113.2ms\n",
      "image 59/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-7-_jpg.rf.512202c5a42762b0f49690329c35a83b.jpg: 640x640 (no detections), 120.1ms\n",
      "image 60/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-8-_jpg.rf.7681257de7781f44dca954bc4f17e6a2.jpg: 640x640 2 not-gos, 127.9ms\n",
      "image 61/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images-9-_jpg.rf.636e5211e85211602d84c7a790234ead.jpg: 640x640 2 not-gos, 126.8ms\n",
      "image 62/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\images_jpg.rf.e5e7217d014a7ec20f29d698befd659b.jpg: 640x640 (no detections), 121.7ms\n",
      "image 63/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\istockphoto-1253851745-612x612_jpg.rf.c506842354c207dbae33a894968496dd.jpg: 640x640 2 not-gos, 118.2ms\n",
      "image 64/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\istockphoto-577633002-612x612_jpg.rf.d85542a783b1f85489517c083a73b528.jpg: 640x640 (no detections), 117.1ms\n",
      "image 65/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\istockphoto-693406474-170667a_jpg.rf.9220bd6f62467e05a37ed4b6074e4825.jpg: 640x640 2 not-gos, 113.0ms\n",
      "image 66/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\istockphoto-950322678-612x612_jpg.rf.91b0dd6b2a3e74b745a5da61b7053705.jpg: 640x640 (no detections), 119.4ms\n",
      "image 67/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\istockphoto-950322682-612x612_jpg.rf.ad3b900e00ddec2081491e62f3505d17.jpg: 640x640 1 not-go, 118.9ms\n",
      "image 68/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\ratio3x2_400_jpg.rf.6e2bef09cc2071ed3ce4bf48eb91f2a5.jpg: 640x640 (no detections), 112.3ms\n",
      "image 69/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-1182-_jpg.rf.269ad59a394995b129321a7506c99abe.jpg: 640x640 1 not-go, 113.0ms\n",
      "image 70/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-1200-_jpg.rf.50e3687dc92e428462c10eead7bacf1a.jpg: 640x640 3 not-gos, 147.5ms\n",
      "image 71/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-1216-_jpg.rf.5a7c7ffe10b7b28c490fdf2d00a8444c.jpg: 640x640 (no detections), 144.6ms\n",
      "image 72/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-329-_jpg.rf.a5c6fda79da3df567c2b98b5e8870e23.jpg: 640x640 2 not-gos, 155.8ms\n",
      "image 73/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-348-_jpg.rf.51fdf325af9124fffb156a31441e9b0b.jpg: 640x640 2 not-gos, 180.7ms\n",
      "image 74/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-353-_jpg.rf.18cc00cca161302421b17770497be1e9.jpg: 640x640 1 not-go, 183.8ms\n",
      "image 75/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-354-_jpg.rf.a68bdce1e442c2f67a0ec0711afd5dba.jpg: 640x640 2 not-gos, 224.0ms\n",
      "image 76/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-365-_jpg.rf.9e2721e45deb536412bb5772408afdb0.jpg: 640x640 3 not-gos, 170.7ms\n",
      "image 77/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-37-_jpg.rf.3af173a50e6e598e52c968ded7dce603.jpg: 640x640 1 go, 2 not-gos, 173.1ms\n",
      "image 78/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-385-_jpg.rf.7dca4e1d7dd574109603f3db7759b26f.jpg: 640x640 2 not-gos, 170.9ms\n",
      "image 79/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-39-_jpg.rf.a2e0b5ecec6e66675d54e6219b7fb0eb.jpg: 640x640 2 not-gos, 183.7ms\n",
      "image 80/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-391-_jpg.rf.3a630961ce7d0e90c0a23134cc441eea.jpg: 640x640 2 not-gos, 179.7ms\n",
      "image 81/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-392-_jpg.rf.45097d67454fa696d4a5f7f700b36836.jpg: 640x640 2 not-gos, 173.8ms\n",
      "image 82/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-394-_jpg.rf.a1c35a79784db1c806e8d41f90b21319.jpg: 640x640 3 not-gos, 161.5ms\n",
      "image 83/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-395-_jpg.rf.187475a76149f442e29d5ee89fe77c28.jpg: 640x640 3 not-gos, 173.8ms\n",
      "image 84/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-397-_jpg.rf.c58dff48f88541a10ab704d87e622458.jpg: 640x640 2 not-gos, 185.8ms\n",
      "image 85/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-405-_jpg.rf.8a078dfd180aaa5f81ffe38642d40d9b.jpg: 640x640 2 not-gos, 179.4ms\n",
      "image 86/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-409-_jpg.rf.ec83e0f8b937241d9f0461fbcae799af.jpg: 640x640 2 not-gos, 161.5ms\n",
      "image 87/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\rpl-433-_jpg.rf.83adbb6d75552b872b388e947d715600.jpg: 640x640 2 not-gos, 172.0ms\n",
      "image 88/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\tflight_001114_jpg.rf.02d778577d10f3b5e85d6f1afc739eb0.jpg: 640x640 (no detections), 173.1ms\n",
      "image 89/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\tflight_001143_jpg.rf.31d2d741c9868d165b8638987ccb584f.jpg: 640x640 (no detections), 181.4ms\n",
      "image 90/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\tflight_001206_jpg.rf.b977e36305b079009f4876a20e5a7d63.jpg: 640x640 (no detections), 186.3ms\n",
      "image 91/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\tflight_001240_jpg.rf.6766ecd1c5a3e09258d37ecace03916d.jpg: 640x640 (no detections), 167.6ms\n",
      "image 92/92 C:\\Users\\wonha\\OneDrive\\Desktop\\Wonha\\UNIV\\Personal_Projects\\Pedestrain_Traffic_Light\\blind_assist1.v2i.yolov8\\test\\images\\tflight_001522_jpg.rf.f6000986780ccc75ea209a3e77079180.jpg: 640x640 (no detections), 149.6ms\n",
      "Speed: 4.2ms preprocess, 150.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the path to the model weights and the source directory of images\n",
    "model_weights = 'runs/detect/train/weights/best.pt'\n",
    "source_images = \"C:/Users/wonha/OneDrive/Desktop/Wonha/UNIV/Personal_Projects/Pedestrain_Traffic_Light/Pedestrian Lights.v1i.yolov8/test/images\"\n",
    "\n",
    "# Create a YOLO object with the specified model weights and set the confidence threshold\n",
    "yolo = YOLO(model_weights)\n",
    "\n",
    "# Run detection on the source images\n",
    "results = yolo.predict(source=source_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python-headless\n",
    "# %pip install lap//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success ✅ (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 480x640 (no detections), 116.6ms\n",
      "0: 480x640 (no detections), 113.6ms\n",
      "0: 480x640 (no detections), 100.2ms\n",
      "0: 480x640 (no detections), 98.9ms\n",
      "0: 480x640 (no detections), 100.1ms\n",
      "0: 480x640 (no detections), 103.8ms\n",
      "0: 480x640 (no detections), 96.0ms\n",
      "0: 480x640 (no detections), 105.0ms\n",
      "0: 480x640 (no detections), 99.6ms\n",
      "0: 480x640 (no detections), 103.8ms\n",
      "0: 480x640 (no detections), 96.6ms\n",
      "0: 480x640 (no detections), 103.1ms\n",
      "0: 480x640 (no detections), 105.1ms\n",
      "0: 480x640 (no detections), 113.0ms\n",
      "0: 480x640 (no detections), 121.8ms\n",
      "0: 480x640 (no detections), 105.7ms\n",
      "0: 480x640 (no detections), 105.4ms\n",
      "0: 480x640 (no detections), 107.8ms\n",
      "0: 480x640 (no detections), 107.6ms\n",
      "0: 480x640 (no detections), 125.9ms\n",
      "0: 480x640 (no detections), 102.9ms\n",
      "0: 480x640 (no detections), 117.3ms\n",
      "0: 480x640 (no detections), 109.4ms\n",
      "0: 480x640 (no detections), 105.9ms\n",
      "0: 480x640 (no detections), 98.7ms\n",
      "0: 480x640 (no detections), 104.6ms\n",
      "0: 480x640 (no detections), 101.3ms\n",
      "0: 480x640 (no detections), 101.2ms\n",
      "0: 480x640 (no detections), 114.2ms\n",
      "0: 480x640 (no detections), 99.0ms\n",
      "0: 480x640 (no detections), 100.5ms\n",
      "0: 480x640 (no detections), 122.9ms\n",
      "0: 480x640 (no detections), 106.7ms\n",
      "0: 480x640 (no detections), 121.2ms\n",
      "0: 480x640 (no detections), 188.8ms\n",
      "0: 480x640 (no detections), 322.4ms\n",
      "0: 480x640 (no detections), 223.1ms\n",
      "0: 480x640 (no detections), 189.4ms\n",
      "0: 480x640 (no detections), 186.6ms\n",
      "0: 480x640 (no detections), 196.9ms\n",
      "0: 480x640 (no detections), 237.3ms\n",
      "0: 480x640 (no detections), 253.6ms\n",
      "0: 480x640 (no detections), 252.0ms\n",
      "0: 480x640 (no detections), 168.2ms\n",
      "0: 480x640 (no detections), 179.0ms\n",
      "0: 480x640 (no detections), 177.4ms\n",
      "0: 480x640 (no detections), 173.3ms\n",
      "0: 480x640 (no detections), 150.5ms\n",
      "0: 480x640 (no detections), 162.1ms\n",
      "0: 480x640 (no detections), 153.5ms\n",
      "0: 480x640 (no detections), 155.0ms\n",
      "0: 480x640 (no detections), 156.7ms\n",
      "0: 480x640 (no detections), 152.6ms\n",
      "0: 480x640 (no detections), 149.5ms\n",
      "0: 480x640 (no detections), 139.6ms\n",
      "0: 480x640 (no detections), 106.3ms\n",
      "0: 480x640 (no detections), 109.8ms\n",
      "0: 480x640 (no detections), 107.4ms\n",
      "0: 480x640 1 green, 112.7ms\n",
      "0: 480x640 (no detections), 108.1ms\n",
      "0: 480x640 (no detections), 105.8ms\n",
      "0: 480x640 1 green, 106.7ms\n",
      "0: 480x640 (no detections), 103.4ms\n",
      "0: 480x640 (no detections), 107.0ms\n",
      "0: 480x640 (no detections), 109.8ms\n",
      "0: 480x640 (no detections), 119.9ms\n",
      "0: 480x640 1 green, 106.3ms\n",
      "0: 480x640 (no detections), 101.6ms\n",
      "0: 480x640 (no detections), 111.3ms\n",
      "0: 480x640 (no detections), 112.0ms\n",
      "0: 480x640 (no detections), 112.5ms\n",
      "0: 480x640 (no detections), 106.6ms\n",
      "0: 480x640 (no detections), 111.5ms\n",
      "0: 480x640 (no detections), 114.9ms\n",
      "0: 480x640 (no detections), 105.5ms\n",
      "0: 480x640 (no detections), 110.7ms\n",
      "0: 480x640 (no detections), 104.0ms\n",
      "0: 480x640 (no detections), 110.3ms\n",
      "0: 480x640 (no detections), 108.0ms\n",
      "0: 480x640 (no detections), 108.7ms\n",
      "0: 480x640 (no detections), 100.0ms\n",
      "0: 480x640 (no detections), 107.7ms\n",
      "0: 480x640 (no detections), 103.2ms\n",
      "0: 480x640 (no detections), 106.3ms\n",
      "0: 480x640 (no detections), 122.3ms\n",
      "0: 480x640 (no detections), 112.5ms\n",
      "0: 480x640 (no detections), 104.9ms\n",
      "0: 480x640 (no detections), 115.3ms\n",
      "0: 480x640 (no detections), 112.7ms\n",
      "0: 480x640 (no detections), 106.3ms\n",
      "0: 480x640 (no detections), 103.2ms\n",
      "0: 480x640 (no detections), 144.7ms\n",
      "0: 480x640 (no detections), 162.6ms\n",
      "0: 480x640 (no detections), 150.6ms\n",
      "0: 480x640 (no detections), 153.8ms\n",
      "0: 480x640 (no detections), 152.8ms\n",
      "0: 480x640 (no detections), 151.7ms\n",
      "0: 480x640 (no detections), 150.7ms\n",
      "0: 480x640 (no detections), 158.5ms\n",
      "0: 480x640 1 green, 196.3ms\n",
      "0: 480x640 (no detections), 161.5ms\n",
      "0: 480x640 (no detections), 148.7ms\n",
      "0: 480x640 (no detections), 168.9ms\n",
      "0: 480x640 (no detections), 159.1ms\n",
      "0: 480x640 1 green, 148.1ms\n",
      "0: 480x640 (no detections), 149.6ms\n",
      "0: 480x640 (no detections), 160.9ms\n",
      "0: 480x640 (no detections), 147.2ms\n",
      "0: 480x640 (no detections), 148.1ms\n",
      "0: 480x640 (no detections), 152.0ms\n",
      "0: 480x640 (no detections), 156.0ms\n",
      "0: 480x640 (no detections), 147.2ms\n",
      "0: 480x640 (no detections), 150.7ms\n",
      "0: 480x640 (no detections), 148.2ms\n",
      "0: 480x640 (no detections), 156.5ms\n",
      "0: 480x640 (no detections), 152.5ms\n",
      "0: 480x640 1 green, 161.1ms\n",
      "0: 480x640 (no detections), 112.4ms\n",
      "0: 480x640 (no detections), 102.7ms\n",
      "0: 480x640 (no detections), 106.5ms\n",
      "0: 480x640 (no detections), 103.4ms\n",
      "0: 480x640 (no detections), 128.1ms\n",
      "0: 480x640 (no detections), 99.1ms\n",
      "0: 480x640 (no detections), 110.1ms\n",
      "0: 480x640 (no detections), 108.0ms\n",
      "0: 480x640 (no detections), 112.0ms\n",
      "0: 480x640 (no detections), 104.1ms\n",
      "0: 480x640 (no detections), 111.9ms\n",
      "0: 480x640 (no detections), 105.6ms\n",
      "0: 480x640 (no detections), 107.7ms\n",
      "0: 480x640 (no detections), 104.4ms\n",
      "0: 480x640 (no detections), 118.8ms\n",
      "0: 480x640 (no detections), 122.1ms\n",
      "0: 480x640 (no detections), 111.7ms\n",
      "0: 480x640 (no detections), 114.1ms\n",
      "0: 480x640 (no detections), 109.1ms\n",
      "0: 480x640 (no detections), 115.8ms\n",
      "0: 480x640 (no detections), 106.7ms\n",
      "0: 480x640 (no detections), 114.1ms\n",
      "0: 480x640 (no detections), 107.0ms\n",
      "0: 480x640 (no detections), 120.3ms\n",
      "0: 480x640 (no detections), 106.4ms\n",
      "0: 480x640 (no detections), 110.5ms\n",
      "0: 480x640 (no detections), 108.0ms\n",
      "0: 480x640 (no detections), 116.8ms\n",
      "0: 480x640 (no detections), 118.6ms\n",
      "0: 480x640 (no detections), 113.9ms\n",
      "0: 480x640 (no detections), 117.1ms\n",
      "0: 480x640 (no detections), 114.5ms\n",
      "0: 480x640 (no detections), 114.7ms\n",
      "0: 480x640 (no detections), 125.9ms\n",
      "0: 480x640 (no detections), 112.6ms\n",
      "0: 480x640 (no detections), 113.8ms\n",
      "0: 480x640 (no detections), 158.9ms\n",
      "0: 480x640 (no detections), 156.7ms\n",
      "0: 480x640 1 green, 154.2ms\n",
      "0: 480x640 (no detections), 155.9ms\n",
      "0: 480x640 1 green, 161.8ms\n",
      "0: 480x640 1 green, 158.3ms\n",
      "0: 480x640 1 green, 166.4ms\n",
      "0: 480x640 1 green, 161.0ms\n",
      "0: 480x640 1 green, 156.9ms\n",
      "0: 480x640 1 green, 161.6ms\n",
      "0: 480x640 1 green, 185.9ms\n",
      "0: 480x640 1 green, 166.0ms\n",
      "0: 480x640 1 green, 151.9ms\n",
      "0: 480x640 1 green, 156.3ms\n",
      "0: 480x640 1 green, 159.0ms\n",
      "0: 480x640 1 green, 161.7ms\n",
      "0: 480x640 1 green, 159.8ms\n",
      "0: 480x640 1 green, 159.5ms\n",
      "0: 480x640 (no detections), 156.6ms\n",
      "0: 480x640 (no detections), 154.2ms\n",
      "0: 480x640 (no detections), 160.2ms\n",
      "0: 480x640 (no detections), 160.2ms\n",
      "0: 480x640 (no detections), 153.8ms\n",
      "0: 480x640 (no detections), 160.1ms\n",
      "0: 480x640 (no detections), 151.8ms\n",
      "0: 480x640 (no detections), 103.6ms\n",
      "0: 480x640 (no detections), 100.8ms\n",
      "0: 480x640 (no detections), 111.7ms\n",
      "0: 480x640 (no detections), 107.5ms\n",
      "0: 480x640 (no detections), 112.7ms\n",
      "0: 480x640 (no detections), 113.7ms\n",
      "0: 480x640 (no detections), 110.5ms\n",
      "0: 480x640 (no detections), 120.9ms\n",
      "0: 480x640 (no detections), 107.3ms\n",
      "0: 480x640 (no detections), 109.8ms\n",
      "0: 480x640 (no detections), 110.5ms\n",
      "0: 480x640 (no detections), 113.7ms\n",
      "0: 480x640 (no detections), 122.5ms\n",
      "0: 480x640 (no detections), 110.3ms\n",
      "0: 480x640 (no detections), 109.5ms\n",
      "0: 480x640 (no detections), 107.9ms\n",
      "0: 480x640 (no detections), 114.9ms\n",
      "0: 480x640 (no detections), 116.7ms\n",
      "0: 480x640 (no detections), 127.8ms\n",
      "0: 480x640 (no detections), 118.8ms\n",
      "0: 480x640 (no detections), 116.0ms\n",
      "0: 480x640 (no detections), 109.6ms\n",
      "0: 480x640 (no detections), 115.0ms\n",
      "0: 480x640 (no detections), 117.6ms\n",
      "0: 480x640 (no detections), 115.9ms\n",
      "0: 480x640 (no detections), 114.6ms\n",
      "0: 480x640 (no detections), 117.9ms\n",
      "0: 480x640 (no detections), 110.4ms\n",
      "0: 480x640 (no detections), 117.7ms\n",
      "0: 480x640 (no detections), 115.1ms\n",
      "0: 480x640 (no detections), 120.0ms\n",
      "0: 480x640 (no detections), 119.4ms\n",
      "0: 480x640 (no detections), 121.2ms\n",
      "0: 480x640 (no detections), 111.8ms\n",
      "0: 480x640 (no detections), 127.5ms\n",
      "0: 480x640 (no detections), 168.5ms\n",
      "0: 480x640 (no detections), 177.5ms\n",
      "0: 480x640 (no detections), 158.3ms\n",
      "0: 480x640 (no detections), 150.8ms\n",
      "0: 480x640 (no detections), 158.5ms\n",
      "0: 480x640 (no detections), 153.6ms\n",
      "0: 480x640 (no detections), 167.8ms\n",
      "0: 480x640 (no detections), 156.6ms\n",
      "0: 480x640 (no detections), 155.9ms\n",
      "0: 480x640 (no detections), 203.7ms\n",
      "0: 480x640 (no detections), 164.1ms\n",
      "0: 480x640 (no detections), 183.6ms\n",
      "0: 480x640 (no detections), 158.0ms\n",
      "0: 480x640 (no detections), 204.8ms\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Open a handle to the default webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Ensure the webcam opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB as Ultralytics YOLO expects RGB images\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform detection\n",
    "    results = model.track(source=0, show=True, tracker='bytetrack.yaml', conf=0.5)\n",
    "\n",
    "    detections = results[0]  # This should now properly contain the detections\n",
    "\n",
    "    # Check if there are any detections\n",
    "    if len(detections) > 0:\n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2, conf, class_id = detection.cpu().numpy()\n",
    "            \n",
    "            label = model.names[int(class_id)]\n",
    "            if label in ['green', 'red']:  # Adjust this label as per your model's output\n",
    "                # Draw bounding box and label on the original frame\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label} {conf:.2f}\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detections\n",
    "    cv2.imshow('Real-time Traffic Light Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
